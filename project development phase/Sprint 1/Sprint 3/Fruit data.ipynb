{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c81e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"id\": \"83c9d9e6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"id\": \"273658b8\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"train_datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"id\": \"873eef43\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"test_datagen=ImageDataGenerator(rescale=1./255)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"id\": \"b4d4807e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Found 5384 images belonging to 6 classes.\\n\",\n",
    "      \"Found 1686 images belonging to 6 classes.\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"x_train=train_datagen.flow_from_directory('fruit-dataset/f_train',\\n\",\n",
    "    \"                                          target_size=(128,128),batch_size=24,class_mode='categorical')\\n\",\n",
    "    \"x_test=test_datagen.flow_from_directory('fruit-dataset/f_test',\\n\",\n",
    "    \"                                        target_size=(128,128),batch_size=24,class_mode='categorical')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"id\": \"936f160a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"{'Apple___Black_rot': 0,\\n\",\n",
    "       \" 'Apple___healthy': 1,\\n\",\n",
    "       \" 'Corn_(maize)___Northern_Leaf_Blight': 2,\\n\",\n",
    "       \" 'Corn_(maize)___healthy': 3,\\n\",\n",
    "       \" 'Peach___Bacterial_spot': 4,\\n\",\n",
    "       \" 'Peach___healthy': 5}\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 6,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"x_train.class_indices\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"id\": \"f685b710\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from tensorflow.keras.models import Sequential\\n\",\n",
    "    \"from tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D,Flatten\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"id\": \"67ad1fde\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model=Sequential()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"id\": \"6c3e7492\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 10,\n",
    "   \"id\": \"abd0543e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.add(MaxPooling2D(pool_size=(2,2)))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 11,\n",
    "   \"id\": \"5a6baee5\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.add(Flatten())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 12,\n",
    "   \"id\": \"bfb83c20\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Model: \\\"sequential\\\"\\n\",\n",
    "      \"_________________________________________________________________\\n\",\n",
    "      \" Layer (type)                Output Shape              Param #   \\n\",\n",
    "      \"=================================================================\\n\",\n",
    "      \" conv2d (Conv2D)             (None, 126, 126, 32)      896       \\n\",\n",
    "      \"                                                                 \\n\",\n",
    "      \" max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \\n\",\n",
    "      \" )                                                               \\n\",\n",
    "      \"                                                                 \\n\",\n",
    "      \" flatten (Flatten)           (None, 127008)            0         \\n\",\n",
    "      \"                                                                 \\n\",\n",
    "      \"=================================================================\\n\",\n",
    "      \"Total params: 896\\n\",\n",
    "      \"Trainable params: 896\\n\",\n",
    "      \"Non-trainable params: 0\\n\",\n",
    "      \"_________________________________________________________________\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 13,\n",
    "   \"id\": \"b9884779\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.add(Dense(300,activation='relu'))\\n\",\n",
    "    \"model.add(Dense(150,activation='relu'))\\n\",\n",
    "    \"model.add(Dense(6,activation='softmax'))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 14,\n",
    "   \"id\": \"b222822d\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 15,\n",
    "   \"id\": \"b36ab5b4\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Epoch 1/10\\n\",\n",
    "      \"225/225 [==============================] - 158s 701ms/step - loss: 1.1387 - accuracy: 0.7624 - val_loss: 0.3235 - val_accuracy: 0.8843\\n\",\n",
    "      \"Epoch 2/10\\n\",\n",
    "      \"225/225 [==============================] - 111s 491ms/step - loss: 0.2539 - accuracy: 0.9116 - val_loss: 0.2671 - val_accuracy: 0.9039\\n\",\n",
    "      \"Epoch 3/10\\n\",\n",
    "      \"225/225 [==============================] - 118s 525ms/step - loss: 0.1975 - accuracy: 0.9329 - val_loss: 0.1724 - val_accuracy: 0.9478\\n\",\n",
    "      \"Epoch 4/10\\n\",\n",
    "      \"225/225 [==============================] - 127s 565ms/step - loss: 0.1653 - accuracy: 0.9421 - val_loss: 0.2982 - val_accuracy: 0.9004\\n\",\n",
    "      \"Epoch 5/10\\n\",\n",
    "      \"225/225 [==============================] - 127s 565ms/step - loss: 0.1533 - accuracy: 0.9461 - val_loss: 0.1494 - val_accuracy: 0.9531\\n\",\n",
    "      \"Epoch 6/10\\n\",\n",
    "      \"225/225 [==============================] - 113s 500ms/step - loss: 0.1154 - accuracy: 0.9573 - val_loss: 0.1461 - val_accuracy: 0.9520\\n\",\n",
    "      \"Epoch 7/10\\n\",\n",
    "      \"225/225 [==============================] - 114s 508ms/step - loss: 0.1154 - accuracy: 0.9625 - val_loss: 0.2850 - val_accuracy: 0.9211\\n\",\n",
    "      \"Epoch 8/10\\n\",\n",
    "      \"225/225 [==============================] - 112s 496ms/step - loss: 0.1047 - accuracy: 0.9627 - val_loss: 0.1464 - val_accuracy: 0.9591\\n\",\n",
    "      \"Epoch 9/10\\n\",\n",
    "      \"225/225 [==============================] - 107s 475ms/step - loss: 0.1242 - accuracy: 0.9567 - val_loss: 0.1058 - val_accuracy: 0.9656\\n\",\n",
    "      \"Epoch 10/10\\n\",\n",
    "      \"225/225 [==============================] - 106s 470ms/step - loss: 0.1006 - accuracy: 0.9651 - val_loss: 0.2158 - val_accuracy: 0.9312\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<keras.callbacks.History at 0x1a4887d1940>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 15,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"model.fit(x_train,steps_per_epoch=len(x_train),validation_data=x_test,validation_steps=len(x_test),epochs=10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 16,\n",
    "   \"id\": \"534b794e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"71/71 - 5s - loss: 0.2158 - accuracy: 0.9312 - 5s/epoch - 67ms/step\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"0.9311981201171875\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 16,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"score,acc=model.evaluate(x_test,batch_size=128,verbose=2)\\n\",\n",
    "    \"acc\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 17,\n",
    "   \"id\": \"4eedcf18\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.save('fruit.h5')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"d21c7390\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"#Testing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 18,\n",
    "   \"id\": \"a4ffd8d0\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from tensorflow.keras.models import load_model\\n\",\n",
    "    \"from tensorflow.keras.preprocessing import image\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 19,\n",
    "   \"id\": \"e3708322\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model=load_model('fruit.h5')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 36,\n",
    "   \"id\": \"8d42f68d\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"1/1 [==============================] - 0s 39ms/step\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"'Apple___Black_rot'\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 36,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"img=image.load_img(\\\"apple_rot.JPG\\\",target_size=(128,128))\\n\",\n",
    "    \"x=image.img_to_array(img)\\n\",\n",
    "    \"x=np.expand_dims(x,axis=0)\\n\",\n",
    "    \"y=np.argmax(model.predict(x),axis=1)\\n\",\n",
    "    \"index=['Apple___Black_rot','Apple___healthy','Corn_(maize)___Northern_Leaf_Blight','Corn_(maize)___healthy','Peach___Bacterial_spot','Peach___healthy']\\n\",\n",
    "    \"index[y[0]]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"78a2a464\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.13\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
